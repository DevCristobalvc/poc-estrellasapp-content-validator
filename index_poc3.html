<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Clasificaci√≥n de Videos | Estrellas App</title>
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', sans-serif;
      background: linear-gradient(90deg, #36d1dc, #5b86e5);
      color: #333;
    }
    header {
      background: #fff;
      border-bottom: 3px solid #ccc;
      text-align: center;
    }
    header img {
      max-width: 10%;
      height: auto;
    }
    .container {
      max-width: 1000px;
      margin: 40px auto;
      padding: 0 20px;
    }
    .problem, .tech, .form-section, .result, .contact {
      background: #fff;
      padding: 20px;
      margin-bottom: 30px;
      border-radius: 12px;
      box-shadow: 0 0 15px rgba(0,0,0,0.05);
    }
    h2 {
      color: #5c2b9e;
    }
    .result {
      text-align: center;
      font-size: 1.5rem;
      font-weight: bold;
      padding: 30px;
    }
    .allowed {
      color: green;
    }
    .not-allowed {
      color: red;
    }
    input[type="file"] {
      padding: 10px;
      font-size: 1rem;
    }
    button {
      padding: 10px 20px;
      margin-top: 15px;
      font-size: 1rem;
      background: #5c2b9e;
      color: #fff;
      border: none;
      border-radius: 6px;
      cursor: pointer;
    }
    button:hover {
      background: #43217c;
    }
    .contact {
      text-align: center;
      font-style: italic;
      font-size: 0.95rem;
    }
  </style>
</head>
<body>

<header>
  <img src="https://www.estrellas.app/wp-content/uploads/2025/03/e-horizontal-gradient.png" alt="Estrellas App" />
  <h1>Clasificador de Contenido - Prueba de Concepto</h1>
</header>

<div class="container">
  <section class="problem">
    <h2>üåç Problem√°tica</h2>
    <p>En el proceso de selecci√≥n y publicaci√≥n de contenido audiovisual para plataformas como Estrellas, se enfrentan desaf√≠os significativos relacionados con la clasificaci√≥n de videos. Actualmente, este proceso es manual, costoso en tiempo y recursos, y adem√°s est√° sujeto a errores humanos. Esto no solo ralentiza el flujo de publicaci√≥n, sino que pone en riesgo la calidad y adecuaci√≥n del contenido ofrecido al p√∫blico objetivo.</p>
    <p>Existe una necesidad urgente de automatizar este an√°lisis para determinar si un video cumple con los criterios de publicaci√≥n, respetando normas de contenido, estilo y mensaje.</p>
  </section>

  <section class="tech">
    <h2>üß† Soluci√≥n t√©cnica con Hugging Face</h2>
    <p>Utilizando modelos de inteligencia artificial disponibles en <strong>Hugging Face</strong>, hemos implementado una soluci√≥n que analiza videos frame por frame para generar una descripci√≥n automatizada del contenido. Esta descripci√≥n es luego procesada para determinar si el video es adecuado para su publicaci√≥n en nuestra plataforma.</p>
    <p>El flujo funciona de la siguiente manera:</p>
    <ol>
      <li>Se selecciona un video local y se extraen fotogramas cada ciertos segundos.</li>
      <li>Cada frame es enviado a un modelo de an√°lisis de im√°genes hospedado en Hugging Face.</li>
      <li>Se genera un resumen descriptivo del contenido visual del video.</li>
      <li>Una capa de inferencia adicional (reglas de negocio o IA) determina si el contenido es apto para ser publicado.</li>
    </ol>
    <p>Esta soluci√≥n no solo mejora la eficiencia, sino que garantiza consistencia, trazabilidad y escalabilidad del proceso editorial audiovisual.</p>
  </section>

  <section class="form-section">
    <h2>üì§ Cargar video para clasificaci√≥n</h2>
    <form id="videoForm">
      <input type="file" id="videoInput" accept="video/*" required />
      <br />
      <button type="submit">Analizar Video</button>
    </form>
  </section>

  <section class="result" id="resultBox">
    üïê Esperando an√°lisis...
  </section>

  <section class="contact">
    Contacto: Cristobal Valencia - üì± 3005412940
  </section>
</div>

<script>
    const fileInput = document.getElementById("fileInput");
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const descripcion = document.getElementById("descripcion");
    const descripcionLista = document.getElementById("descripcionLista");
    const previewImage = document.getElementById("previewImage");
    const moduloValidacion = document.getElementById("moduloValidacion");
  
    const frasesPermitidas = [
      "una mujer hablando", "personas en una reuni√≥n", "una entrevista",
      "una escena tranquila", "una mujer sonriendo", "gente colaborando"
    ];
  
    fileInput.addEventListener("change", function () {
      const file = this.files[0];
      const url = URL.createObjectURL(file);
  
      descripcionLista.innerHTML = '';
      moduloValidacion.innerHTML = "üîç Esperando an√°lisis...";
      descripcion.style.display = "none";
  
      if (file.type.startsWith("video/")) {
        video.src = url;
        video.style.display = "block";
        previewImage.style.display = "none";
      } else if (file.type.startsWith("image/")) {
        previewImage.src = url;
        previewImage.style.display = "block";
        video.style.display = "none";
      }
    });
  
    async function analizarContenido() {
      const file = fileInput.files[0];
      const context = canvas.getContext("2d");
      descripcionLista.innerHTML = '';
      descripcion.style.display = "block";
  
      if (file.type.startsWith("image/")) {
        const img = new Image();
        img.src = URL.createObjectURL(file);
        await img.decode();
        canvas.width = img.width;
        canvas.height = img.height;
        context.drawImage(img, 0, 0);
        const blob = await new Promise(resolve => canvas.toBlob(resolve, "image/jpeg"));
        await enviarABlip(blob);
      } else if (file.type.startsWith("video/")) {
        const frames = [1, 3, 5];
        for (let i = 0; i < frames.length; i++) {
          await extraerYAnalizarFrame(frames[i]);
        }
      }
    }
  
    function extraerYAnalizarFrame(segundo) {
      return new Promise(resolve => {
        video.currentTime = segundo;
        video.onseeked = async () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          canvas.getContext("2d").drawImage(video, 0, 0, canvas.width, canvas.height);
          const blob = await new Promise(r => canvas.toBlob(r, "image/jpeg"));
          await enviarABlip(blob);
          resolve();
        };
      });
    }
  
    async function enviarABlip(blob) {
      const response = await fetch("https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base", {
        method: "POST",
        headers: {
          "Authorization": "Bearer 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",
          "Content-Type": "application/octet-stream"
        },
        body: blob
      });
  
      const data = await response.json();
      const texto = data[0]?.generated_text || "Descripci√≥n no disponible.";
      const li = document.createElement("li");
      li.textContent = texto;
      descripcionLista.appendChild(li);
  
      validarContenido(texto);
    }
  
    function validarContenido(texto) {
      const esPermitido = frasesPermitidas.some(frase => texto.toLowerCase().includes(frase));
      if (esPermitido) {
        moduloValidacion.innerHTML = "‚úÖ Video permitido. Contenido aceptable.";
        moduloValidacion.style.backgroundColor = "#d4edda";
      } else {
        moduloValidacion.innerHTML = "‚ùå Video no permitido. Revisi√≥n necesaria.";
        moduloValidacion.style.backgroundColor = "#f8d7da";
      }
    }
  </script>

</body>
</html>